{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web-scraping: сбор данных из баз данных и интернет-источников\n",
    "\n",
    "*Алла Тамбовцева, НИУ ВШЭ*\n",
    "\n",
    "## Практикум 5*. Работа с текстами: анализ тональности \n",
    "\n",
    "### Часть 1: подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем библиотеку `pandas`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1HCg6V1oMy9H"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сейчас мы будем работать с готовым файлом `comments-as-rows.csv`, в котором сохранены все посты со стены [сообщества](https://vk.com/rzclimbing) скалодрома RockZona ВКонтакте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1GRbdPG_M4UW"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"comments_as_rows.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пояснения по названиям столбцов:\n",
    "    \n",
    "* `post_id`: id поста;\n",
    "* `post_date`: дата публикации поста (POSIX формат);\n",
    "* `post_text`: текст поста;\n",
    "* `nlikes`: число лайков;\n",
    "* `nreposts`: число репостов;\n",
    "* `comm_id`: id комментария; \n",
    "* `comm_date`: дата публикации комментария (POSIX формат);\n",
    "* `user_id`: id пользователя, оставившего комментарий;\n",
    "* `comm_text`: текст комментария;\n",
    "* `thread`: ответы на комментарий в виде словаря с разными характеристиками.\n",
    "\n",
    "В полученном датафрейме одна строка соответствует одному комментарию, а не посту, поэтому id, тексты и прочие характеристики постов повторяются, а вот комментарии от строки к строке меняются. \n",
    "\n",
    "Оставим в датафрейме `df` только те строки, которые соответствуют постам с текстом. Можно удалить строки с пропусками, а мы, наоборот, выберем те строки, где значение `post_text` непустое, применив метод `.notnull()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NFZ6Pp9_M548"
   },
   "outputs": [],
   "source": [
    "df = df[df[\"post_text\"].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как впереди нам предстоит работать исключительно с постами, давайте получим сокращённую версию датафрейма – избавимся от строк с повторяющимися значениями в столбце `post_id`, оставив только последнее из повторений (можно забрать и первое, отличия только в комментариях, а нас они пока не интересуют):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C3Sxnz54M7ms"
   },
   "outputs": [],
   "source": [
    "df_post = df.drop_duplicates(subset = \"post_id\", keep = \"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_post.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично! Формат датафрейма подходит для дальнейшей задачи – анализа тональности постов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 2: анализ тональности с билиотекой `dostoevsky`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Анализ тональности – определение эмоциональной окрашенности текста. С его помощью можно определить, позитивный ли перед нами текст, негативный или вообще нейтральный. \n",
    "\n",
    "Для анализа тональности мы будем использовать библиотеку `dostoevsky`. Эта библиотека разработана специально для русского языка, к тому же в неё входит модель, которая обучена на текстах из социальных сетей, что делает её особенно полезной для решения прикладных задач (всё-таки алгоритмы, которые учатся распознавать тональность текстов на твитах, постах или отзывах ближе к реальности, чем алгоритмы, обученные на стандартном корпусе литературных текстов).\n",
    "\n",
    "Использовать библиотеку довольно просто, достаточно повторить действия, описанные в [документации](https://github.com/bureaucratic-labs/dostoevsky), однако с установкой библиотеки иногда возникают сложности. Проблема заключается в том, что эта библиотека зависит от библиотеки `fasttext`, которая используется для быстрой обработки текстов на разных языках, а она, в свою очередь, не работает на Windows без специальных дополнений, позволющих запускать код на C++ (собственно, именно из-за «ядра» на C++ всё быстро и работает).\n",
    "\n",
    "Итак, порядок действий такой:\n",
    "\n",
    "1. Попробовать запустить код `!pip install dostoevsky` для установки библиотеки в Jupyter. Если выводится ошибка, связанная с отсутствием/невозможностью установить `fasttext`, пробуем установить `fasttext` через `!pip install fasttext`. \n",
    "\n",
    "2. При установке `fasttext` Python выдаст сообщение об ошибке с актуальной ссылкой на Visual Studio C++ Build Tools. Если позволяет память компьютера, лучше установить все компоненты для простоты, но если хочется сократить список, можно выбрать только ключевые, см. перечень [здесь](https://medium.com/@oleg.tarasov/building-fasttext-python-wrapper-from-source-under-windows-68e693a68cbb) в *Step 2*.\n",
    "\n",
    "3. После установки компонентов Visual Studio C++ Build Tools (ключевое – это компилятор кода на C++) снова пробуем установить `fasttext` через `!pip install fasttext` или сразу `dostoevsky` через  `!pip install dostoevsky`. Должно установиться! \n",
    "\n",
    "В крайнем случае можно установить `dostoevsky` в Google Colab, среда находится на сервере, работающим на Ubuntu, это Unix-система, не Windows.\n",
    "\n",
    "Устанавливаем библиотеку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WNuCIy5vM9QF",
    "outputId": "a45231a0-b9df-457d-d368-220772b29d9c"
   },
   "outputs": [],
   "source": [
    "!pip install dostoevsky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После успешной установки скачиваем модель, которая будет предсказывать тональность текста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r2ILPPPVNAVW"
   },
   "outputs": [],
   "source": [
    "!python -m dostoevsky download fasttext-social-network-model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем классы `RegexTokenizer` и `FastTextSocialNetworkModel`, которые позволят создать токенизатор (инструмент для правильного разбиения текста на слова) и модель для предсказания тональности текста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5KY3l8nrNjyA"
   },
   "outputs": [],
   "source": [
    "from dostoevsky.tokenization import RegexTokenizer\n",
    "from dostoevsky.models import FastTextSocialNetworkModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс – это довольно абстрактная вещь, это некоторый объект и его описание одновременно. Например, в библиотеке `pandas` ключевой объект – это датафрейм. Это класс, названный `DataFrame`, на котором разработчики библиотеки определили разные атрибуты и методы (и они же определили, как они работают). Так, с помощью функции `DataFrame()` мы создаём новый датафрейм, а затем можем применять к нему различные методы вроде `.describe()`, `.head()`, `.dropna()`. \n",
    "\n",
    "Здесь происходит то же самое, только создаются более непривычные объекты со своими методами и характеристиками:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MZBv3vcSN_yd",
    "outputId": "6228b25a-effd-4152-d298-d3c0998c48bc"
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexTokenizer()\n",
    "model = FastTextSocialNetworkModel(tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, применяя метод `.predict()` к модели, которую мы определили ранее, мы сможем предсказать вероятности того, что текст поста относится к тому или иному типу. Всего в данной модели предусмотрено 5 типов:\n",
    "\n",
    "* `positive`: положительно окрашенный;\n",
    "* `negative`: отрицательно окрашенный;\n",
    "* `neutral`: нейтральный;\n",
    "* `speech`: приветствия, благодарности и подобные элементы речи;\n",
    "* `skip`: неидентифицируемые случаи (реклама, шутки, цитаты, стихи);\n",
    "\n",
    "Эти типы «унаследованы» от проекта [RuSentiment](https://github.com/text-machine-lab/rusentiment).\n",
    "\n",
    "Мы выберем все 5 типов, потому что при меньшем числе типов будут отобраны самые вероятные, а они у разных постов будут разные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-f1xomMUOh9K"
   },
   "outputs": [],
   "source": [
    "results = model.predict(df_post[\"post_text\"], k = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как модель уже готова и загружена, предсказание вероятностей происходит очень быстро. Посмотрим на первый результат – описание первого поста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат представлен в виде словаря, где ключами являются названия типов, а значениями – вероятности, с которыми текст можно отнести к этому типу, согласно модели. Сохраним все эти вероятности в отдельный столбец датафрейма:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L2zjmBwuPOyQ"
   },
   "outputs": [],
   "source": [
    "df_post[\"results\"] = results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь по уже знакомой схеме извлечём из словаря вероятности для трёх самых понятных типов (положительный, отрицательный, нейтральный):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fJt8zcT1PVJ7",
    "outputId": "1c7d024e-cafa-456e-cf43-b85f6aa023f4"
   },
   "outputs": [],
   "source": [
    "df_post[\"positive\"] = df_post[\"results\"].apply(lambda x: x[\"positive\"])\n",
    "df_post[\"negative\"] = df_post[\"results\"].apply(lambda x: x[\"negative\"])\n",
    "df_post[\"neutral\"] = df_post[\"results\"].apply(lambda x: x[\"neutral\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_post.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем, например, сортировать посты по степени их «позитивности»:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# топ 10 положительно окрашенных постов\n",
    "\n",
    "df_post.sort_values(\"positive\", ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Или «негативности»:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 635
    },
    "id": "A_G_bsAUPv3M",
    "outputId": "29f3a118-1cac-4ad4-d494-0f024936b9e7"
   },
   "outputs": [],
   "source": [
    "# топ 10 отрицательно окрашенных постов\n",
    "# с определением негатива тут есть проблемы\n",
    "\n",
    "df_post.sort_values(\"negative\", ascending = False).head(10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
